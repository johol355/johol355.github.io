{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dependencies\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine, text\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Import parsing functions\n",
    "import sys\n",
    "sys.path.append('/Users/JO/PhD/neurocritical-transfers/utils')\n",
    "import hems\n",
    "import metar_parse\n",
    "\n",
    "# Define the SQLalchemy engine\n",
    "engine = create_engine(f\"sqlite:////Users/JO/PhD/neurocritical-transfers/data/db.sqlite\")\n",
    "\n",
    "# Read the SQL query from the file\n",
    "with open('/Users/JO/PhD/neurocritical-transfers/notes/final-analysis/0-database-query/primary-based-transfer-query.sql', 'r') as file:\n",
    "    query = file.read()\n",
    "\n",
    "# Execute the query\n",
    "d = pd.read_sql(query, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to data\n",
    "PATH_METAR='/Users/JO/PhD/neurocritical-transfers/data/metar'\n",
    "PATH_AIRPORT_COORDS='/Users/JO/PhD/neurocritical-transfers/data/icu-airport-mapping-with-coordinates.csv'\n",
    "\n",
    "# Load and parse weather data\n",
    "weather_parsed = metar_parse.get_metar_data(PATH_METAR, PATH_AIRPORT_COORDS)\n",
    "weather = weather_parsed.copy()\n",
    "weather['hems_minima'] = weather.apply(hems.hems_minima, axis=1)\n",
    "weather = hems.hems_minima_window(weather, window='121Min')\n",
    "\n",
    "# Get the list of unique airports\n",
    "airports = weather['icao'].unique()\n",
    "\n",
    "# Add month to dataset\n",
    "weather['month'] = weather['time_utc'].dt.month\n",
    "\n",
    "# Calculate the number of rows and columns for subplots\n",
    "num_airports = len(airports)\n",
    "num_cols = 3  # Number of columns\n",
    "num_rows = -(-num_airports // num_cols)  # Ceiling division to get the number of rows\n",
    "\n",
    "# national mean \n",
    "countrywide_mean = weather.query(\"icao not in ['ESGT', 'ESGP']\").groupby('month')['hems_minima'].mean() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remmap receiving hospital codes to names\n",
    "hospitals_map = {\"11001\": \"Karolinska universitetssjukhuset, Solna\",\n",
    " \"11003\": \"Karolinska universitetssjukhuset, Solna\",\n",
    " \"51001\": \"Sahlgrenska universitetssjukhuset\",\n",
    " \"12001\": \"Akademiska sjukhuset\",\n",
    " \"21001\": \"Universitetssjukhuset i Linköping\",\n",
    " \"64001\": \"Norrlands universitetssjukhus\",\n",
    " \"41001\": \"Universitetssjukhuset i Lund\",\n",
    " \"41002\": \"Universitetssjukhuset i Lund\"}\n",
    "d['tertiary_center'] = d.tertiary_center_id.map(hospitals_map)\n",
    "\n",
    "# Fix admission time so that time zone is clear, also add a admission time in UTC for later merging of data\n",
    "d[\"sir_adm_time\"] = pd.to_datetime(d[\"sir_adm_time\"], unit='s').dt.tz_localize('Europe/Stockholm')\n",
    "d['admission_time_utc'] = d[\"sir_adm_time\"].dt.tz_convert('UTC')\n",
    "\n",
    "# Load dataframes of formatted ICU names and ICU to airport mappings\n",
    "icu_names = pd.read_csv('/Users/JO/PhD/neurocritical-transfers/data/icu-mapping-names-only.csv', sep=\";\")\n",
    "airports = pd.read_csv('/Users/JO/PhD/neurocritical-transfers/data/icu-airport-mapping.csv', sep=\";\")\n",
    "airports_sending = airports.rename({'formatted_icu_name': 'sir_icu_name'}, axis=1).add_prefix('sending_')\n",
    "airports_receiving = airports.rename({'formatted_icu_name': 'tertiary_center'}, axis=1).add_prefix('receiving_')\n",
    "\n",
    "# Remap ICU names to properly formatted ICU names\n",
    "icu_names_dict = dict(zip(icu_names['sir_icu_name'], icu_names['formatted_icu_name']))\n",
    "d.sir_icu_name = d.sir_icu_name.map(icu_names_dict)\n",
    "\n",
    "# Merge dataframes with sending and receiving airports dataframes\n",
    "d_with_sending_icao = pd.merge(d, airports_sending, left_on='sir_icu_name', right_on='sending_sir_icu_name',  how='left')\n",
    "d_with_receiving_icao = pd.merge(d_with_sending_icao, airports_receiving, left_on='tertiary_center', right_on='receiving_tertiary_center',  how='left')\n",
    "d_with_airports = d_with_receiving_icao.sort_values(by=['admission_time_utc'])\n",
    "\n",
    "# \"Duplicate\" the weather dataframe into two separate df with prefixes \"sending\" and \"receiving\" before merging with the clinical data\n",
    "sending_weather = weather.sort_values(by=['time_utc']).add_prefix('sending_')\n",
    "receiving_weather = weather.sort_values(by=['time_utc']).add_prefix('receiving_')\n",
    "\n",
    "# Merge the dataframe with METAR observations and HEMS inferences for both sending and receving hospitals within 30 minutes of the ICU admission\n",
    "s_df = pd.merge_asof(d_with_airports, sending_weather, by='sending_icao', left_on='admission_time_utc', right_on='sending_time_utc', tolerance=pd.Timedelta(30, unit='min'), direction='nearest')\n",
    "r_df = pd.merge_asof(s_df, receiving_weather, by='receiving_icao', left_on='admission_time_utc', right_on='receiving_time_utc', tolerance=pd.Timedelta(30, unit='min'), direction='nearest')\n",
    "\n",
    "# Check is HEMS minima at point estimates or windows are met at both places\n",
    "r_df['both_point_hems_minima'] = (\n",
    "    (r_df['sending_hems_minima'] & r_df['receiving_hems_minima'])\n",
    "    .where(\n",
    "        ~r_df['sending_hems_minima'].isna() & ~r_df['receiving_hems_minima'].isna(), np.nan)\n",
    ")\n",
    "\n",
    "r_df['both_hems_minima_window'] = (\n",
    "    (r_df['sending_hems_minima_window'] & r_df['receiving_hems_minima_window'])\n",
    "    .where(\n",
    "        ~r_df['sending_hems_minima_window'].isna() & ~r_df['receiving_hems_minima_window'].isna(), np.nan)\n",
    ")\n",
    "\n",
    "# Choose columns\n",
    "final_d = r_df\n",
    "\n",
    "# Limit the data to hospitals that are presumed to be frequent users of hems\n",
    "hems_users = [\"Arvika IVA\", \"Bollnäs IVA\", \"Eskilstuna IVA\", \"Falun IVA\", \"Gällivare IVA\", \"Gävle IVA\", \"Hudiksvall IVA\", \"Karlstad IVA\", \"Lycksele IVA\", \"Mora IVA\",  \"Östersund IVA\", \"Skövde IVA\", \"Torsby IVA\", \"Trollhättan IVA\", \"Västerås IVA\", \"Visby IVA\"]\n",
    "\n",
    "hems_d = final_d[final_d.sir_icu_name.isin(hems_users)]\n",
    "hems_d['utc_month']=hems_d.admission_time_utc.dt.month\n",
    "hems_d['utc_day']=hems_d.admission_time_utc.dt.dayofyear\n",
    "hems_d['utc_hour']=hems_d.admission_time_utc.dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hems_d.to_csv('hems_d.csv')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
